{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPD5rkg8ZO1d2TPV8NYDHvW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"CnhYj6VDDtOY","executionInfo":{"status":"ok","timestamp":1719548853516,"user_tz":-540,"elapsed":7772,"user":{"displayName":"hoyA","userId":"08797501018688592510"}}},"outputs":[],"source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Embedding\n","from tensorflow.keras.utils import to_categorical"]},{"cell_type":"code","source":["# text_to_word_sequence\n","\n","from tensorflow.keras.preprocessing.text import text_to_word_sequence\n","\n","text = '해보지 않으면 해낼 수 없다. 당신이 선택한 데싸의 길 후회하지 말라'\n","\n","# 토큰화\n","# >> 문장(sequence) 을 단어(word) 로 토큰화 해 줌\n","text_to_word_sequence(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3kgE1RG7GPjp","executionInfo":{"status":"ok","timestamp":1719548936067,"user_tz":-540,"elapsed":327,"user":{"displayName":"hoyA","userId":"08797501018688592510"}},"outputId":"b94c9b15-3676-4329-b57f-6ff17669cb4b"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['해보지', '않으면', '해낼', '수', '없다', '당신이', '선택한', '데싸의', '길', '후회하지', '말라']"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["result = text_to_word_sequence(text)\n","print('원문 : ',text)\n","print('토큰화된 문장 : ',result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cobv1RlIGnyk","executionInfo":{"status":"ok","timestamp":1719548972669,"user_tz":-540,"elapsed":328,"user":{"displayName":"hoyA","userId":"08797501018688592510"}},"outputId":"bb128047-5120-481b-bda0-300aacbd2075"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["원문 :  해보지 않으면 해낼 수 없다. 당신이 선택한 데싸의 길 후회하지 말라\n","토큰화된 문장 :  ['해보지', '않으면', '해낼', '수', '없다', '당신이', '선택한', '데싸의', '길', '후회하지', '말라']\n"]}]},{"cell_type":"code","source":["# 단어 빈도 체크\n","\n","# 전처리 하려는 세 개의 문장\n","docs = ['먼저 텍스트의 각 단어를 나누어 토큰화 합니다.',\n","       '텍스트의 단어로 토큰화해야 딥러닝에서 인식됩니다.',\n","       '토큰화한 결과는 딥러닝에서 사용할 수 있습니다.',\n","       ]\n","\n","# 토큰화 (전처리)\n","token = Tokenizer()       # 토큰화 함수 사용\n","token.fit_on_texts(docs)  # 토큰화 함수를 문장에 적용"],"metadata":{"id":"brMCHMHRGuKJ","executionInfo":{"status":"ok","timestamp":1719549087216,"user_tz":-540,"elapsed":338,"user":{"displayName":"hoyA","userId":"08797501018688592510"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# 단어 빈도수 계산\n","print('단어 카운트 : \\n', token.word_counts)  # 단어(word) 빈도 세어 줌\n","print()\n","print('문장 카운트: \\n', token.document_count) # 문장(document) 빈도 세어 줌\n","print()\n","print('각 단어가 몇개의 문장에 포함되어 있는지 확인: \\n', token.word_docs)\n","print()\n","print('각 단어에 매겨진 index값: ',token.word_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PB05dvL9HMsC","executionInfo":{"status":"ok","timestamp":1719549289942,"user_tz":-540,"elapsed":6,"user":{"displayName":"hoyA","userId":"08797501018688592510"}},"outputId":"66d1fff9-f77b-45c9-f883-7f8b9a75bb83"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["단어 카운트 : \n"," OrderedDict([('먼저', 1), ('텍스트의', 2), ('각', 1), ('단어를', 1), ('나누어', 1), ('토큰화', 1), ('합니다', 1), ('단어로', 1), ('토큰화해야', 1), ('딥러닝에서', 2), ('인식됩니다', 1), ('토큰화한', 1), ('결과는', 1), ('사용할', 1), ('수', 1), ('있습니다', 1)])\n","\n","문장 카운트: \n"," 3\n","\n","각 단어가 몇개의 문장에 포함되어 있는지 확인: \n"," defaultdict(<class 'int'>, {'단어를': 1, '토큰화': 1, '나누어': 1, '텍스트의': 2, '먼저': 1, '합니다': 1, '각': 1, '토큰화해야': 1, '딥러닝에서': 2, '단어로': 1, '인식됩니다': 1, '토큰화한': 1, '수': 1, '결과는': 1, '있습니다': 1, '사용할': 1})\n","\n","각 단어에 매겨진 index값:  {'텍스트의': 1, '딥러닝에서': 2, '먼저': 3, '각': 4, '단어를': 5, '나누어': 6, '토큰화': 7, '합니다': 8, '단어로': 9, '토큰화해야': 10, '인식됩니다': 11, '토큰화한': 12, '결과는': 13, '사용할': 14, '수': 15, '있습니다': 16}\n"]}]},{"cell_type":"code","source":["# 단어 one-hot encoding\n","text = '오랫동안 꿈꾸는 이는 그 꿈을 닮아간다.'\n","법사위원장 = '님들은 멋대로 했지만 우리는 법대로 한다.'\n","\n","token = Tokenizer()\n","token.fit_on_texts([text])\n","print(token.word_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sHd2WxFWHTDr","executionInfo":{"status":"ok","timestamp":1719549431184,"user_tz":-540,"elapsed":322,"user":{"displayName":"hoyA","userId":"08797501018688592510"}},"outputId":"d59240eb-95a7-4ca3-81a8-0cc66a6cc235"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["{'오랫동안': 1, '꿈꾸는': 2, '이는': 3, '그': 4, '꿈을': 5, '닮아간다': 6}\n"]}]},{"cell_type":"code","source":["token_law = Tokenizer()\n","token_law.fit_on_texts([법사위원장])\n","print(token_law.word_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IElXJnuhJGhQ","executionInfo":{"status":"ok","timestamp":1719549623816,"user_tz":-540,"elapsed":338,"user":{"displayName":"hoyA","userId":"08797501018688592510"}},"outputId":"852576fa-e2bb-4b05-d6dd-544ff5136ec3"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["{'님들은': 1, '멋대로': 2, '했지만': 3, '우리는': 4, '법대로': 5, '한다': 6}\n"]}]},{"cell_type":"code","source":["token.texts_to_sequences([text])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vF7sXxMyIgqy","executionInfo":{"status":"ok","timestamp":1719549450896,"user_tz":-540,"elapsed":307,"user":{"displayName":"hoyA","userId":"08797501018688592510"}},"outputId":"07f6140f-6b6a-43b9-ea7b-3eb4b25a701b"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1, 2, 3, 4, 5, 6]]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["token_law.texts_to_sequences([법사위원장])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yqGAmdV_JTi9","executionInfo":{"status":"ok","timestamp":1719549646014,"user_tz":-540,"elapsed":307,"user":{"displayName":"hoyA","userId":"08797501018688592510"}},"outputId":"9cbdd94b-f2de-4709-d321-5f1ce8804bde"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1, 2, 3, 4, 5, 6]]"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["x = token.texts_to_sequences([text])"],"metadata":{"id":"-ltpeWkUIleu","executionInfo":{"status":"ok","timestamp":1719549466383,"user_tz":-540,"elapsed":294,"user":{"displayName":"hoyA","userId":"08797501018688592510"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["jcr = token_law.texts_to_sequences([법사위원장])"],"metadata":{"id":"sIT6hVmpJY9Y","executionInfo":{"status":"ok","timestamp":1719549671599,"user_tz":-540,"elapsed":317,"user":{"displayName":"hoyA","userId":"08797501018688592510"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# index + 1 one-hot encoding 만들기\n","word_size = len(token.word_index) + 1 # 1 을 더하는 것에 주의\n","word_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X6eyaDi5IpQy","executionInfo":{"status":"ok","timestamp":1719549535122,"user_tz":-540,"elapsed":421,"user":{"displayName":"hoyA","userId":"08797501018688592510"}},"outputId":"9c248a8d-7be3-45bd-c5f2-3c23b6abeea7"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["word_size = len(token_law.word_index) + 1\n","word_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RUnu8IpZJcg3","executionInfo":{"status":"ok","timestamp":1719549705585,"user_tz":-540,"elapsed":307,"user":{"displayName":"hoyA","userId":"08797501018688592510"}},"outputId":"636138a6-3342-46bb-cc96-5b54eb6773d0"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["to_categorical(jcr, num_classes = word_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oq6EUdagI6BC","executionInfo":{"status":"ok","timestamp":1719549713242,"user_tz":-540,"elapsed":313,"user":{"displayName":"hoyA","userId":"08797501018688592510"}},"outputId":"7cbf8589-ed86-40cd-848d-5026744bc30a"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[0., 1., 0., 0., 0., 0., 0.],\n","        [0., 0., 1., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0.],\n","        [0., 0., 0., 0., 1., 0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0.],\n","        [0., 0., 0., 0., 0., 0., 1.]]], dtype=float32)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["# 감성분석 (긍정/부정 예측)\n","\n","import numpy as np\n","\n","docs = [\"너무 재밌네요\",\"최고예요\",\"참 잘 만든 영화예요\",\"추천하고 싶은 영화입니다\",\"한번 더 보고싶네요\",\n","        \"글쎄요\",\"별로예요\",\"생각보다 지루하네요\",\"연기가 어색해요\",\"재미없어요\"]\n","\n","# 긍정 리뷰(1), 부정 리뷰(0)\n","cls = np.array([1,1,1,1,1,0,0,0,0,0])"],"metadata":{"id":"qDiOsSLzJAbK","executionInfo":{"status":"ok","timestamp":1719549820709,"user_tz":-540,"elapsed":310,"user":{"displayName":"hoyA","userId":"08797501018688592510"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# 토큰화\n","token = Tokenizer()\n","token.fit_on_texts(docs)\n","print(token.word_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"75yVfuPNJ_xQ","executionInfo":{"status":"ok","timestamp":1719549853966,"user_tz":-540,"elapsed":309,"user":{"displayName":"hoyA","userId":"08797501018688592510"}},"outputId":"2a71bbf7-06c7-478e-9ac7-d42aabd8a98d"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["{'너무': 1, '재밌네요': 2, '최고예요': 3, '참': 4, '잘': 5, '만든': 6, '영화예요': 7, '추천하고': 8, '싶은': 9, '영화입니다': 10, '한번': 11, '더': 12, '보고싶네요': 13, '글쎄요': 14, '별로예요': 15, '생각보다': 16, '지루하네요': 17, '연기가': 18, '어색해요': 19, '재미없어요': 20}\n"]}]},{"cell_type":"code","source":["x = token.texts_to_sequences(docs)\n","x\n","# x : 토큰화된 결과"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pfd96FbDKH4t","executionInfo":{"status":"ok","timestamp":1719549897308,"user_tz":-540,"elapsed":339,"user":{"displayName":"hoyA","userId":"08797501018688592510"}},"outputId":"c1988e1b-c111-4c70-fd3f-110330158f1d"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1, 2],\n"," [3],\n"," [4, 5, 6, 7],\n"," [8, 9, 10],\n"," [11, 12, 13],\n"," [14],\n"," [15],\n"," [16, 17],\n"," [18, 19],\n"," [20]]"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["# 단어의 길이를 맞추어 줘야 해요 >> padding(zero padding)\n","\n","pad_sequences(x,4) # x라는 입력받은 문장을 4의 길이로 맞춰줘"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"11QRC3YYKPMw","executionInfo":{"status":"ok","timestamp":1719549968616,"user_tz":-540,"elapsed":334,"user":{"displayName":"hoyA","userId":"08797501018688592510"}},"outputId":"b4f7a101-9b7a-4a5b-daee-091ff0786a70"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0,  0,  1,  2],\n","       [ 0,  0,  0,  3],\n","       [ 4,  5,  6,  7],\n","       [ 0,  8,  9, 10],\n","       [ 0, 11, 12, 13],\n","       [ 0,  0,  0, 14],\n","       [ 0,  0,  0, 15],\n","       [ 0,  0, 16, 17],\n","       [ 0,  0, 18, 19],\n","       [ 0,  0,  0, 20]], dtype=int32)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["padded_x = pad_sequences(x,4)"],"metadata":{"id":"c9A9qtBLKj31","executionInfo":{"status":"ok","timestamp":1719549999162,"user_tz":-540,"elapsed":312,"user":{"displayName":"hoyA","userId":"08797501018688592510"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["from collections.abc import Sequence\n","# 임베딩에 입력될 단어 수 지지어\n","\n","word_size = len(token.word_index) + 1\n","\n","# 단어 임베딩 포함. 딥러닝 모델 만들기\n","model = Sequential()\n","model.add(Embedding(word_size, 16, input_length=4))\n","model.add(Flatten())\n","model.add(Dense(1, activation='sigmoid'))\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DuLJYtQGKrVo","executionInfo":{"status":"ok","timestamp":1719550176535,"user_tz":-540,"elapsed":468,"user":{"displayName":"hoyA","userId":"08797501018688592510"}},"outputId":"b423b502-44ea-49cb-8de0-dbb64e02cbab"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 4, 16)             336       \n","                                                                 \n"," flatten (Flatten)           (None, 64)                0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 401 (1.57 KB)\n","Trainable params: 401 (1.57 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.compile(loss='binary_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","model.fit(padded_x, cls, epochs=20)\n","print('ACC: %.4f'%(model.evaluate(padded_x, cls)[1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k714yOxvLWdN","executionInfo":{"status":"ok","timestamp":1719550345374,"user_tz":-540,"elapsed":2590,"user":{"displayName":"hoyA","userId":"08797501018688592510"}},"outputId":"ecec3a14-ef63-468a-aec6-a044416044b5"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","1/1 [==============================] - 1s 988ms/step - loss: 0.6951 - accuracy: 0.5000\n","Epoch 2/20\n","1/1 [==============================] - 0s 13ms/step - loss: 0.6925 - accuracy: 0.6000\n","Epoch 3/20\n","1/1 [==============================] - 0s 14ms/step - loss: 0.6899 - accuracy: 0.7000\n","Epoch 4/20\n","1/1 [==============================] - 0s 13ms/step - loss: 0.6873 - accuracy: 0.7000\n","Epoch 5/20\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6847 - accuracy: 0.8000\n","Epoch 6/20\n","1/1 [==============================] - 0s 15ms/step - loss: 0.6821 - accuracy: 0.8000\n","Epoch 7/20\n","1/1 [==============================] - 0s 19ms/step - loss: 0.6796 - accuracy: 0.8000\n","Epoch 8/20\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6770 - accuracy: 0.8000\n","Epoch 9/20\n","1/1 [==============================] - 0s 16ms/step - loss: 0.6744 - accuracy: 0.8000\n","Epoch 10/20\n","1/1 [==============================] - 0s 18ms/step - loss: 0.6718 - accuracy: 0.9000\n","Epoch 11/20\n","1/1 [==============================] - 0s 17ms/step - loss: 0.6691 - accuracy: 0.9000\n","Epoch 12/20\n","1/1 [==============================] - 0s 16ms/step - loss: 0.6665 - accuracy: 0.9000\n","Epoch 13/20\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6639 - accuracy: 0.9000\n","Epoch 14/20\n","1/1 [==============================] - 0s 17ms/step - loss: 0.6612 - accuracy: 0.9000\n","Epoch 15/20\n","1/1 [==============================] - 0s 16ms/step - loss: 0.6585 - accuracy: 0.9000\n","Epoch 16/20\n","1/1 [==============================] - 0s 13ms/step - loss: 0.6558 - accuracy: 0.9000\n","Epoch 17/20\n","1/1 [==============================] - 0s 19ms/step - loss: 0.6531 - accuracy: 0.9000\n","Epoch 18/20\n","1/1 [==============================] - 0s 19ms/step - loss: 0.6503 - accuracy: 0.9000\n","Epoch 19/20\n","1/1 [==============================] - 0s 12ms/step - loss: 0.6476 - accuracy: 0.9000\n","Epoch 20/20\n","1/1 [==============================] - 0s 13ms/step - loss: 0.6448 - accuracy: 0.9000\n","1/1 [==============================] - 0s 232ms/step - loss: 0.6419 - accuracy: 0.9000\n","ACC: 0.9000\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"jdeLnwlML_To"},"execution_count":null,"outputs":[]}]}